{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TADbit tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TADbit also provides a set of command line tools that are installed with the library and that cover the main functionalities.\n",
    "\n",
    "This tools are idependent but share a working directory where a local database is created to store the input/outputs of each process or job, and also some statistics.\n",
    "\n",
    "Each of these tools has extensive help, so we will here review only their general usage and function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TADbit map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Map Hi-C reads and organize results in an output working directory\n",
    "\n",
    "usage: tadbit map [-h] [--skip_mapping] -w PATH --fastq PATH [--fastq2 PATH] --index PATH\n",
    "                  [--genome PATH [PATH ...]] --read INT --renz STR [STR ...]\n",
    "                  [--chr_name STR [STR ...]] [--tmp PATH] [--tmpdb PATH] [--noX] [--iterative]\n",
    "                  [--fast_fragment] [--windows WINDOWS [WINDOWS ...]] [--species STR]\n",
    "                  [--descr LIST [LIST ...]] [--skip] [--keep_tmp] [-C CPUS] [--mapper STR]\n",
    "                  [--mapper_binary STR] [--mapper_param MAPPER_PARAM [MAPPER_PARAM ...]]\n",
    "\n",
    "optional arguments:\n",
    "  -h, --help               show this help message and exit\n",
    "\n",
    "General options:\n",
    "  --skip_mapping           generate a Hi-C specific quality plot from FASTQ and exits\n",
    "  -w PATH, --workdir PATH  path to an output folder.\n",
    "  --fastq PATH             path to a FASTQ files (can be compressed files)\n",
    "  --fastq2 PATH            (beta) path to a FASTQ file of read 2 (can be compressed files).\n",
    "                           Needed for fast_fragment\n",
    "  --index PATH             paths to file(s) with indexed FASTA files of the reference genome.\n",
    "  --genome PATH [PATH ...]\n",
    "                           paths to file(s) with FASTA files of the reference genome. Needed\n",
    "                           for fast_fragment mapping. If many, files will be concatenated.\n",
    "                           I.e.: --genome chr_1.fa chr_2.fa In this last case, order is\n",
    "                           important or the rest of the analysis. Note: it can also be the path\n",
    "                           to a previously parsed genome in pickle format.\n",
    "  --read INT               read number\n",
    "  --renz STR [STR ...]     restriction enzyme name(s). Use \"--renz CHECK\" to search for most\n",
    "                           probable and exit; and use \"--renz NONE\" to avoid using RE site\n",
    "                           information.\n",
    "  --chr_name STR [STR ...]\n",
    "                           [fasta header] chromosome name(s). Used in the same order as data.\n",
    "  --tmp PATH               path to a temporary directory (default next to \"workdir\" directory)\n",
    "  --tmpdb PATH             if provided uses this directory to manipulate the database\n",
    "  --noX                    no display server (X screen)\n",
    "  --skip                   [DEBUG] in case already mapped.\n",
    "  --keep_tmp               [DEBUG] keep temporary files.\n",
    "\n",
    "Mapping options:\n",
    "  --iterative              default mapping strategy is fragment based use this flag for\n",
    "                           iterative mapping\n",
    "  --fast_fragment          (beta) use fast fragment mapping. Both fastq files are mapped using\n",
    "                           fragment based mapping in GEM v3. The output file is an intersected\n",
    "                           read file than can be used directly in tadbit filter (no tadbit\n",
    "                           parse needed). Access to samtools is needed for fast_fragment to\n",
    "                           work. --fastq2 and --genome needs to be specified and --read value\n",
    "                           should be 0.\n",
    "  --windows WINDOWS [WINDOWS ...]\n",
    "                           defines windows to be used to trim the input FASTQ reads, for\n",
    "                           example an iterative mapping can be defined as: \"--windows 1:20 1:25\n",
    "                           1:30 1:35 1:40 1:45 1:50\". But this parameter can also be used for\n",
    "                           fragment based mapping if for example pair-end reads are both in the\n",
    "                           same FASTQ, for example: \"--windows 1:50\" (if the length of the\n",
    "                           reads is 100). Note: that the numbers are both inclusive.\n",
    "  -C CPUS, --cpus CPUS     [32] Maximum number of CPU cores available in the execution host. If\n",
    "                           higher than 1, tasks with multi-threading capabilities will enabled\n",
    "                           (if 0 all available) cores will be used\n",
    "  --mapper STR             [gem] mapper used, options are gem, bowtie2 or hisat2\n",
    "  --mapper_binary STR      [None] path to mapper binary\n",
    "  --mapper_param MAPPER_PARAM [MAPPER_PARAM ...]\n",
    "                           any parameter that could be passed to the GEM, BOWTIE2 or HISAT2\n",
    "                           mapper. e.g. if we want to set the proportion of mismatches to 0.05\n",
    "                           and the maximum indel length to 10, (in GEM v2 it would be: -e 0.05\n",
    "                           --max-big-indel-length 10), here we could write: \"--mapper_param\n",
    "                           e:0.05 max-big-indel-length:10\". For BOWTIE2, GEM3 and HISAT2 you\n",
    "                           can also pass directly the parameters enclosed between quotes like:\n",
    "                           --mapper_param \"-e 0.05 --alignment-local-min-score 15\" IMPORTANT:\n",
    "                           some options are incompatible with 3C-derived experiments.\n",
    "\n",
    "Descriptive, optional arguments:\n",
    "  --species STR            species name\n",
    "  --descr LIST [LIST ...]  extra descriptive fields each filed separated by coma, and inside\n",
    "                           each, name and value separated by column:\n",
    "                           --descr=cell:lymphoblast,flowcell:C68AEACXX,index:24nf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TADbit parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Parse mapped Hi-C reads and get the intersection\n",
    "\n",
    "usage: tadbit parse [-h] [-w PATH] [--type STR] [--read INT] [--mapped1 PATHs [PATHs ...]]\n",
    "                    [--mapped2 PATHs [PATHs ...]] [--renz STR] [--filter_chrom FILTER_CHROM]\n",
    "                    [--skip] [--compress_input] [--tmpdb PATH] [--genome PATH [PATH ...]]\n",
    "                    [--jobids INT [INT ...]] [--noX]\n",
    "\n",
    "optional arguments:\n",
    "  -h, --help               show this help message and exit\n",
    "\n",
    "General options:\n",
    "  -w PATH, --workdir PATH  path to working directory (generated with the tool tadbit mapper)\n",
    "  --type STR               [map]file type to be parser, MAP (GEM-mapper), SAM or BAM\n",
    "  --read INT               In case only one of the reads needs to be parsed\n",
    "  --filter_chrom FILTER_CHROM\n",
    "                           default: --filter_chrom\n",
    "                           \"^(chr)?[A-Za-z]?[0-9]{0,3}[XVI]{0,3}(?:ito)?[A-Z-a-z]?(_dna)?$\",\n",
    "                           regexp to consider only chromosome names passing\n",
    "  --skip                   [DEBUG] in case already mapped.\n",
    "  --compress_input         Compress input mapped files when parsing is done. This is done in\n",
    "                           background, while next MAP file is processed, or while reads are\n",
    "                           sorted.\n",
    "  --tmpdb PATH             if provided uses this directory to manipulate the database\n",
    "  --genome PATH [PATH ...]\n",
    "                           paths to file(s) with FASTA files of the reference genome. If many,\n",
    "                           files will be concatenated. I.e.: --genome chr_1.fa chr_2.fa In this\n",
    "                           last case, order is important or the rest of the analysis. Note: it\n",
    "                           can also be the path to a previously parsed genome in pickle format.\n",
    "  --jobids INT [INT ...]   Use as input data generated by a job with a given jobid(s). Use\n",
    "                           tadbit describe to find out which. In this case one jobid can be\n",
    "                           passed per read.\n",
    "  --noX                    no display server (X screen)\n",
    "\n",
    "Mapped outside TADbit options:\n",
    "  --mapped1 PATHs [PATHs ...]\n",
    "                           paths to mapped bam files (first read-end)\n",
    "  --mapped2 PATHs [PATHs ...]\n",
    "                           paths to mapped bam files (second read-end)\n",
    "  --renz STR               restriction enzyme name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TADbit filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Filter parsed Hi-C reads and get valid pair of reads to work with\n",
    "\n",
    "usage: tadbit filter [-h] [--force] [--resume] [--apply INT [INT ...]] [-w PATH] [-C CPUS]\n",
    "                     [--noX] [--over_represented NUM] [--strict_duplicates]\n",
    "                     [--max_frag_size NUM] [--min_frag_size NUM] [--re_proximity NUM]\n",
    "                     [--mad NUM] [--max_f NUM] [--median NUM] [--tmpdb PATH]\n",
    "                     [--pathids INT [INT ...]] [--compress_input] [--format {short,mid,long}]\n",
    "                     [--valid] [--clean] [--samtools PATH]\n",
    "\n",
    "optional arguments:\n",
    "  -h, --help               show this help message and exit\n",
    "\n",
    "General options:\n",
    "  --force                  overwrite previously run job\n",
    "  --resume                 use filters of previously run job\n",
    "  -w PATH, --workdir PATH  path to working directory (generated with the tool tadbit mapper)\n",
    "  -C CPUS, --cpus CPUS     [32] Maximum number of CPU cores available in the execution host. If\n",
    "                           higher than 1, tasks with multi-threading capabilities will enabled\n",
    "                           (if 0 all available) cores will be used\n",
    "  --noX                    no display server (X screen)\n",
    "  --tmpdb PATH             if provided uses this directory to manipulate the database\n",
    "  --pathids INT [INT ...]  Use as input data generated by a job under a given pathids. Use\n",
    "                           tadbit describe to find out which. To filter an intersected file\n",
    "                           produced with tadbit map --fast_fragment only one PATHid is needed\n",
    "                           otherwise one per read is needed, first for read 1, second for read\n",
    "                           2.\n",
    "  --compress_input         Compress input mapped files when parsing is done. This is done in\n",
    "                           background, while next MAP file is processed, or while reads are\n",
    "                           sorted.\n",
    "  --samtools PATH          path samtools binary\n",
    "\n",
    "Storage options:\n",
    "  --format {short,mid,long}\n",
    "                           [mid] for compression into pseudo-BAM format. Short contains only\n",
    "                           positions of reads mapped, mid everything but restriction sites.\n",
    "  --valid                  stores only valid-pairs discards filtered out reads.\n",
    "  --clean                  remove intermediate files. WARNING: together with format \"short\" or\n",
    "                           valid options, this may results in losing data\n",
    "\n",
    "Filtering options:\n",
    "  --apply INT [INT ...]    [[1, 2, 3, 4, 6, 7, 9, 10]] Use filters to define a set os valid\n",
    "                           pair of reads e.g.: '--apply 1 2 3 4 6 7 8 9'. Where these\n",
    "                           numberscorrespond to: 1: self-circle, 2: dangling-end, 3: error, 4:\n",
    "                           extra dangling-end, 5: too close from RES, 6: too short, 7: too\n",
    "                           large, 8: over-represented, 9: duplicated, 10: random breaks\n",
    "  --over_represented NUM   [0.001%] percentage of restriction-enzyme (RE) genomic fragments\n",
    "                           with more coverage to exclude (possible PCR artifact).\n",
    "  --strict_duplicates      by default reads are considered duplicates if they coincide in\n",
    "                           genomic coordinates and strand; with strict_duplicates enabled, we\n",
    "                           also ask to consider read length (WARNING: this option is called\n",
    "                           strict, but it is more permissive)\n",
    "  --max_frag_size NUM      [100000] to exclude large genomic RE fragments (probably resulting\n",
    "                           from gaps in the reference genome)\n",
    "  --min_frag_size NUM      [50] to exclude small genomic RE fragments (smaller than sequenced\n",
    "                           reads)\n",
    "  --re_proximity NUM       [5] to exclude read-ends falling too close from RE site (pseudo-\n",
    "                           dangling-ends)\n",
    "  --mad NUM                MAD fragment length normally computed from observed distribution\n",
    "  --max_f NUM              Maximum fragment length normally computed from observed distribution\n",
    "  --median NUM             Median fragment length normally computed from observed distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TADbit normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Normalize Hi-C data and generates array of biases\n",
    "\n",
    "usage: tadbit normalize [-h] -w PATH -r INT [--bam PATH] [-j INT] [--max_njobs INT]\n",
    "                        [--tmpdb PATH] [-C CPUS] [--normalize_only] [--noX]\n",
    "                        [--normalization STR] [--biases_path BIASES_PATH] [--mappability PATH]\n",
    "                        [--fasta PATH] [--renz STR] [--factor NUM] [--prop_data FLOAT]\n",
    "                        [--seed INT] [--min_count INT] [--cis_limit CIS_LIMIT]\n",
    "                        [--trans_limit TRANS_LIMIT] [--ratio_limit RATIO_LIMIT]\n",
    "                        [--cistrans_filter] [--filter_only]\n",
    "                        [-B CHR:POS1-POS2 [CHR:POS1-POS2 ...]] [-F INT [INT ...]] [--valid]\n",
    "\n",
    "normalize Hi-C data and generates array of biases\n",
    "\n",
    "optional arguments:\n",
    "  -h, --help               show this help message and exit\n",
    "\n",
    "Required options:\n",
    "  -w PATH, --workdir PATH  path to working directory (generated with the tool tadbit mapper)\n",
    "  -r INT, --resolution INT\n",
    "                           resolution at which to output matrices\n",
    "\n",
    "General options:\n",
    "  --bam PATH               path to a TADbit-generated BAM file with all reads (other wise the\n",
    "                           tool will guess from the working directory database)\n",
    "  -j INT, --jobid INT      Use as input data generated by a job with a given jobid. Use tadbit\n",
    "                           describe to find out which.\n",
    "  --max_njobs INT          [100] Define maximum number of jobs for reading BAM file (set to\n",
    "                           higher numbers for large files and low RAM memory).\n",
    "  --tmpdb PATH             if provided uses this directory to manipulate the database\n",
    "  -C CPUS, --cpus CPUS     [32] Maximum number of CPU cores available in the execution host. If\n",
    "                           higher than 1, tasks with multi-threading capabilities will enabled\n",
    "                           (if 0 all available) cores will be used\n",
    "  --normalize_only         skip calculation of Cis-percentage and decay\n",
    "  --noX                    no display server (X screen)\n",
    "\n",
    "Bin filtering options:\n",
    "  --min_count INT          [None] minimum number of reads mapped to a bin (recommended value\n",
    "                           could be 2500). If set this option overrides the perc_zero\n",
    "                           filtering... This option is slightly slower.\n",
    "  --cis_limit CIS_LIMIT    Maximum distance in bins at which to consider an interaction cis for\n",
    "                           the filtering. By default it is the number of bins corresponding to\n",
    "                           1Mb\n",
    "  --trans_limit TRANS_LIMIT\n",
    "                           Maximum distance in bins at which to consider an interaction trans\n",
    "                           for the filtering. By default it is five times the cis_limit (if\n",
    "                           also default, it would correspond to the number of bins needed to\n",
    "                           reach 5Mb).\n",
    "  --ratio_limit RATIO_LIMIT\n",
    "                           [1.0] Minimum cis/trans (as defined with cis_limit and trans_limit\n",
    "                           parameters) to filter out bins.\n",
    "  --cistrans_filter        filter using cis-trans ratio.\n",
    "  --filter_only            skip normalization\n",
    "  -B CHR:POS1-POS2 [CHR:POS1-POS2 ...], --badcols CHR:POS1-POS2 [CHR:POS1-POS2 ...]\n",
    "                           extra regions to be added to bad-columns (ingenomic position). e.g.:\n",
    "                           --badcols 1:150000000-160000000 2:1200000-1300000\n",
    "\n",
    "Read filtering options:\n",
    "  -F INT [INT ...], --filter INT [INT ...]\n",
    "                           [[1, 2, 3, 4, 6, 7, 9, 10]] Use filters to define a set os valid\n",
    "                           pair of reads e.g.: '--apply 1 2 3 4 8 9 10'. Where these\n",
    "                           numberscorrespond to: 1: self-circle, 2: dangling-end, 3: error, 4:\n",
    "                           extra dangling-end, 5: too close from RES, 6: too short, 7: too\n",
    "                           large, 8: over-represented, 9: duplicated, 10: random breaks, 11:\n",
    "                           trans-chromosomic\n",
    "  --valid                  input BAM file contains only valid pairs (already filtered).\n",
    "\n",
    "Normalization options:\n",
    "  --normalization STR      [Vanilla] normalization(s) to apply. Order matters. Choices:\n",
    "                           Vanilla, ICE, SQRT, oneD, custom\n",
    "  --biases_path BIASES_PATH\n",
    "                           biases file to compute decay. REQUIRED with \"custom\" normalization.\n",
    "                           Format: single column with header\n",
    "  --mappability PATH       Path to mappability bedGraph file, required for oneD normalization.\n",
    "                           Mappability file can be generated with GEM (example from the genomic FASTA file hg38.fa):\n",
    "                           \n",
    "                                gem-indexer -i hg38.fa -o hg38\n",
    "                                gem-mappability -I hg38.gem -l 50 -o hg38.50mer -T 8\n",
    "                                gem-2-wig -I hg38.gem -i hg38.50mer.mappability -o hg38.50mer\n",
    "                                wigToBigWig hg38.50mer.wig hg38.50mer.sizes hg38.50mer.bw\n",
    "                                bigWigToBedGraph hg38.50mer.bw  hg38.50mer.bedGraph\n",
    "  --fasta PATH             Path to FASTA file with genome sequence, to compute GC content and\n",
    "                           number of restriction sites per bin. Required for oneD normalization\n",
    "  --renz STR               restriction enzyme name(s). Required for oneD normalization\n",
    "  --factor NUM             [1] target mean value of a cell after normalization (can be used to\n",
    "                           weight experiments before merging)\n",
    "  --prop_data FLOAT        [1] Only for oneD normalization: proportion of data to be used in\n",
    "                           fitting (for very large datasets). Number between 0 and 1.\n",
    "  --seed INT               [1] Only for oneD normalization: seed number for the random picking\n",
    "                           of data when using the \"prop_data\" parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TADbit bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bin Hi-C data into matrices\n",
    "\n",
    "usage: tadbit bin [-h] -w PATH [--noX] -r INT [--bam PATH] [-j INT] [--force] [-q]\n",
    "                  [--tmpdb PATH] [--nchunks NCHUNKS] [-C CPUS] [--chr_name STR [STR ...]]\n",
    "                  [--matrix] [--cooler] [--rownames] [--plot] [--force_plot] [--only_plot] [-i]\n",
    "                  [--triangular] [--xtick_rotation XTICK_ROTATION] [--cmap CMAP]\n",
    "                  [--bad_color BAD_COLOR] [--format FORMAT] [--zrange ZRANGE]\n",
    "                  [--transform {log2,log,none}] [--figsize FIGSIZE] [--tad_def TAD_DEF] [-c]\n",
    "                  [-c2] [--biases PATH] [--norm STR [STR ...]] [-F INT [INT ...]] [--only_txt]\n",
    "\n",
    "optional arguments:\n",
    "  -h, --help               show this help message and exit\n",
    "\n",
    "Required options:\n",
    "  -w PATH, --workdir PATH  path to working directory (generated with the tool tadbit mapper)\n",
    "  -r INT, --resolution INT\n",
    "                           resolution at which to output matrices\n",
    "\n",
    "General options:\n",
    "  --noX                    no display server (X screen)\n",
    "  --bam PATH               path to a TADbit-generated BAM file with all reads (other wise the\n",
    "                           tool will guess from the working directory database)\n",
    "  -j INT, --jobid INT      Use as input data generated by a job with a given jobid. Use tadbit\n",
    "                           describe to find out which.\n",
    "  --force                  overwrite previously run job\n",
    "  -q, --quiet              remove all messages\n",
    "  --tmpdb PATH             if provided uses this directory to manipulate the database\n",
    "  --nchunks NCHUNKS        maximum number of chunks into which to cut the BAM\n",
    "  -C CPUS, --cpus CPUS     [32] Maximum number of CPU cores available in the execution host. If\n",
    "                           higher than 1, tasks with multi-threading capabilities will enabled\n",
    "                           (if 0 all available) cores will be used\n",
    "  --chr_name STR [STR ...]\n",
    "                           [fasta header] chromosome name(s). Order of chromosomes in the\n",
    "                           output matrices.\n",
    "\n",
    "Read filtering options:\n",
    "  -F INT [INT ...], --filter INT [INT ...]\n",
    "                           [[1, 2, 3, 4, 6, 7, 9, 10]] Use filters to define a set os valid\n",
    "                           pair of reads e.g.: '--apply 1 2 3 4 8 9 10'. Where these\n",
    "                           numberscorrespond to: 0: nothing, 1: self-circle, 2: dangling-end,\n",
    "                           3: error, 4: extra dangling-end, 5: too close from RES, 6: too\n",
    "                           short, 7: too large, 8: over-represented, 9: duplicated, 10: random\n",
    "                           breaks, 11: trans-chromosomic\n",
    "\n",
    "Normalization options:\n",
    "  --biases PATH            path to file with pre-calculated biases by columns\n",
    "  --norm STR [STR ...]     [['raw']] normalization(s) to apply. Choices are: [norm, decay, raw,\n",
    "                           raw&decay]\n",
    "\n",
    "Output options:\n",
    "  --matrix                 Write text matrix in multiple columns (square). By defaults matrices\n",
    "                           are written in BED-like format (also only way to get a raw matrix\n",
    "                           with all values including the ones in masked columns).\n",
    "  --cooler                 Write i,j,v matrix in cooler format instead of text.\n",
    "  --rownames               To store row names in the output text matrix. WARNING: when non-\n",
    "                           matrix, results in two extra columns\n",
    "  --only_plot              [False] Skip writing matrix in text format.\n",
    "  -i, --interactive        [False] Open matplotlib interactive plot (nothing will be saved).\n",
    "  -c , --coord             Coordinate of the region to retrieve. By default all genome,\n",
    "                           arguments can be either one chromosome name, or the coordinate in\n",
    "                           the form: \"-c chr3:110000000-120000000\"\n",
    "  -c2 , --coord2           Coordinate of a second region to retrieve the matrix in the\n",
    "                           intersection with the first region.\n",
    "  --only_txt               Save only text file for matrices, not images\n",
    "\n",
    "Plotting options:\n",
    "  --plot                   Plot matrix in desired format.\n",
    "  --force_plot             Force plotting even with demoniacally big matrices (more than\n",
    "                           5000x5000, or 1500x1500with interactive option).\n",
    "  --triangular             [False] represents only half matrix. Note that this also results in\n",
    "                           truly vectorial images of matrix.\n",
    "  --xtick_rotation XTICK_ROTATION\n",
    "                           [-25] x-tick rotation\n",
    "  --cmap CMAP              [viridis] Matplotlib color map to use.\n",
    "  --bad_color BAD_COLOR    [white] Matplotlib color to use on bins filtered out (only used with\n",
    "                           normalized matrices, not raw).\n",
    "  --format FORMAT          [png] plot file format.\n",
    "  --zrange ZRANGE          Range, in log2 scale of the color scale. i.e.: --zrange=-2,2\n",
    "  --transform {log2,log,none}\n",
    "                           [log2] can be any of [log2, log, none]\n",
    "  --figsize FIGSIZE        Range, in log2 scale of the color scale. default for triangular\n",
    "                           matrices: --figsize=16,10 and for square matrices: --figsize=16,14\n",
    "  --tad_def TAD_DEF        jobid with the TAD segmentation, alternatively a tsv file with tad\n",
    "                           definition, columns: # start end score density"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TADbit segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Finds TAD or compartment segmentation in Hi-C data.\n",
    "\n",
    "usage: tadbit segment [-h] -w PATH [--tmpdb PATH] [--nosql] [--all_bins] [--mreads PATH]\n",
    "                      [--biases PATH] -r INT [--norm_matrix PATH] [--raw_matrix PATH]\n",
    "                      [-F INT [INT ...]] [--noX] [--rich_in_A PATH] [--fasta PATH] [--savecorr]\n",
    "                      [--fix_corr_scale] [--format FORMAT] [--n_evs INT]\n",
    "                      [--ev_index INT [INT ...]] [--only_compartments] [--only_tads] [-v]\n",
    "                      [-j INT] [-c STR [STR ...]] [--max_tad_size INT] [-C CPUS] [--force]\n",
    "\n",
    "optional arguments:\n",
    "  -h, --help               show this help message and exit\n",
    "\n",
    "General options:\n",
    "  -w PATH, --workdir PATH  path to working directory (generated with the tool tadbit mapper)\n",
    "  --tmpdb PATH             if provided uses this directory to manipulate the database\n",
    "  --nosql                  do not load/store data from/in sqlite database\n",
    "  --all_bins               skip the filtering of bins for detection of TADs\n",
    "  --mreads PATH            path valid-pairs file (TADbit BAM format)\n",
    "  --biases PATH            path to file with precalculated biases by columns\n",
    "  -r INT, --resolution INT\n",
    "                           resolution at which to output matrices\n",
    "  --norm_matrix PATH       path to a matrix file with normalized read counts\n",
    "  --raw_matrix PATH        path to a matrix file with raw read counts\n",
    "  -F INT [INT ...], --filter INT [INT ...]\n",
    "                           [[1, 2, 3, 4, 6, 7, 9, 10]] Use filters to define a set os valid\n",
    "                           pair of reads e.g.: '--apply 1 2 3 4 8 9 10'. Where these\n",
    "                           numberscorrespond to: 1: self-circle, 2: dangling-end, 3: error, 4:\n",
    "                           extra dangling-end, 5: too close from RES, 6: too short, 7: too\n",
    "                           large, 8: over-represented, 9: duplicated, 10: random breaks, 11:\n",
    "                           trans-chromosomic\n",
    "  --noX                    no display server (X screen)\n",
    "  --only_compartments      search A/B compartments using first eigen vector of the correlation\n",
    "                           matrix\n",
    "  --only_tads              search TAD boundaries break-point detection algorithm\n",
    "  -v, --verbose            print more messages\n",
    "  -j INT, --jobid INT      Use as input data generated by a job with a given jobid. Use tadbit\n",
    "                           describe to find out which.\n",
    "  -c STR [STR ...], --chromosomes STR [STR ...]\n",
    "                           Name of the chromosomes on which to search for TADs or compartments.\n",
    "  -C CPUS, --cpu CPUS      [32] Maximum number of CPU cores available in the execution host. If\n",
    "                           higher than 1, tasks with multi-threading capabilities will enabled\n",
    "                           (if 0 all available) cores will be used\n",
    "  --force                  overwrite previously run job\n",
    "\n",
    "Compartment calling options:\n",
    "  --rich_in_A PATH         path to a BED or bedGraph file with list of protein coding gene or\n",
    "                           other active epigenetic mark, to be used to label compartments\n",
    "                           instead of using the relative interaction count.\n",
    "  --fasta PATH             Path to fasta file with genome sequence, to compute GC content and\n",
    "                           use it to label compartments\n",
    "  --savecorr               Save correlation matrix used to predict compartments.\n",
    "  --fix_corr_scale         Correlation matrix plot scaled between correlation 1 and -1 instead\n",
    "                           of maximum observed values.\n",
    "  --format FORMAT          [png] file format for figures\n",
    "  --n_evs INT              [3] Number of eigenvectors to store. if \"-1\" all eigenvectors will\n",
    "                           be calculated\n",
    "  --ev_index INT [INT ...]\n",
    "                           list of indexes of eigenvectors capturing compartments signal (one\n",
    "                           index per chromosome, in the same order as chromosomes in fasta\n",
    "                           file). Example picking the first eigenvector for all chromosomes but\n",
    "                           for chromosome 3: '--ev_index 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
    "                           1 1 1 1\n",
    "\n",
    "TAD calling options:\n",
    "  --max_tad_size INT       an integer defining the maximum size of TAD. Default defines it as\n",
    "                           the number of rows/columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TADbit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Generates 3D models given an input interaction matrix and a set of input parameters\n",
    "\n",
    "usage: tadbit model [-h] -w PATH [--input_matrix PATH] [--rand INT] [--nmodels INT]\n",
    "                    [--nkeep INT] [-j INT] [--optimization_id INT] [--restart_id INT]\n",
    "                    [--fig_format STR] [--noX] [--corr STR] [--species STRING]\n",
    "                    [--assembly STRING] [--cell STRING] [--exp_type STRING] [--project STRING]\n",
    "                    [--crm NAME] [--beg INT] [--end INT] [--matrix_beg INT] [-r INT]\n",
    "                    [--perc_zero FLOAT] [--smooth_factor INT] [--optimize] [--model]\n",
    "                    [--model_ptadbit] [--force] [--maxdist LIST [LIST ...]]\n",
    "                    [--upfreq LIST [LIST ...]] [--lowfreq LIST [LIST ...]]\n",
    "                    [--scale LIST [LIST ...]] [--dcutoff LIST [LIST ...]]\n",
    "                    [--container LIST [LIST ...]] [--analyze] [-C CPUS] [--job_list]\n",
    "                    [--nmodels_per_job INT] [--cpus_per_job INT] [--concurrent_jobs INT]\n",
    "                    [--timeout_job INT] [--script_cmd STR] [--script_args STR]\n",
    "                    [--script_template STR] [--tmpdb PATH] [--analyze_list INT [INT ...]]\n",
    "                    [--not_write_cmm] [--not_write_xyz] [--not_write_json]\n",
    "\n",
    "Generates 3D models given an input interaction matrix and a set of input parameters\n",
    "\n",
    "optional arguments:\n",
    "  -h, --help               show this help message and exit\n",
    "\n",
    "General options:\n",
    "  -w PATH, --workdir PATH  path to working directory (generated with the tool TADbit mapper)\n",
    "  --input_matrix PATH      In case input was not generated with the TADbit tools\n",
    "  --rand INT               [1] random initial number. NOTE: when running single model at the\n",
    "                           time, should be different for each run\n",
    "  --nmodels INT            [5000] number of models to generate for modeling\n",
    "  --nkeep INT              [1000] number of models to keep for modeling\n",
    "  -j INT, --jobid INT      Use as input data generated by a job with a given jobid. Use tadbit\n",
    "                           describe to find out which.\n",
    "  --optimization_id INT    [None] ID of a pre-run optimization batch job\n",
    "  --restart_id INT         [None] ID of a job to be restarted, for example after building the\n",
    "                           models in a cluster\n",
    "  --fig_format STR         file format and extension for figures and plots (can be any\n",
    "                           supported by matplotlib, png, eps...)\n",
    "  --noX                    no display server (X screen)\n",
    "  --corr STR               correlation method to compare contact maps and original matrix\n",
    "                           (options are speraman, pearson, kendall, logpearson, chi2, scc )\n",
    "\n",
    "Descriptive, optional arguments:\n",
    "  --species STRING         species name, with no spaces, i.e.: homo_sapiens\n",
    "  --assembly STRING        NCBI ID of the original assembly (i.e.: NCBI36 for human)\n",
    "  --cell STRING            cell type name\n",
    "  --exp_type STRING        experiment type name (i.e.: Hi-C)\n",
    "  --project STRING         project name\n",
    "\n",
    "Modeling preparation:\n",
    "  --crm NAME               chromosome name\n",
    "  --beg INT                genomic coordinate from which to start modeling\n",
    "  --end INT                genomic coordinate where to end modeling\n",
    "  --matrix_beg INT         genomic coordinate of the first row/column of the input matrix. This\n",
    "                           has to be specified if the input matrix is not the TADbit tools\n",
    "                           generated abc format\n",
    "  -r INT, --reso INT       resolution of the Hi-C experiment\n",
    "  --perc_zero FLOAT\n",
    "\n",
    "Parameter optimization:\n",
    "  --optimize               optimization run, store less info about models\n",
    "  --model                  modelling run\n",
    "  --model_ptadbit          modelling run using pTADbit\n",
    "  --force                  use input parameters, and skip any precalculated optimization\n",
    "  --maxdist LIST [LIST ...]\n",
    "                           range of numbers for maxdist, i.e. 400:1000:100 -- or just a number\n",
    "                           -- or a list of numbers\n",
    "  --upfreq LIST [LIST ...]\n",
    "                           range of numbers for upfreq, i.e. 0:1.2:0.3 -- or just a number --\n",
    "                           or a list of numbers\n",
    "  --lowfreq LIST [LIST ...]\n",
    "                           range of numbers for lowfreq, i.e. -1.2:0:0.3 -- or just a number --\n",
    "                           or a list of numbers\n",
    "  --scale LIST [LIST ...]  [0.01] range of numbers to be test as optimal scale value, i.e.\n",
    "                           0.005:0.01:0.001 -- Can also pass only one number -- or a list of\n",
    "                           numbers\n",
    "  --dcutoff LIST [LIST ...]\n",
    "                           [2] range of numbers to be test as optimal distance cutoff parameter\n",
    "                           (distance, in number of beads, from which to consider 2 beads as\n",
    "                           being close), i.e. 1:1.5:0.5 -- Can also pass only one number -- or\n",
    "                           a list of numbers\n",
    "  --container LIST [LIST ...]\n",
    "                           restrains particle to be within a given object. Can only be a\n",
    "                           'cylinder', which is, in fact a cylinder of a given height to which\n",
    "                           are added hemispherical ends. This cylinder is defined by a radius,\n",
    "                           its height (with a height of 0 the cylinder becomes a sphere) and\n",
    "                           the force applied to the restraint. E.g. for modeling E. coli genome\n",
    "                           (2 micrometers length and 0.5 micrometer of width), these values\n",
    "                           could be used: 'cylinder' 250 1500 50, and for a typical mammalian\n",
    "                           nuclei (6 micrometers diameter): 'cylinder' 3000 0 50\n",
    "  --analyze                analyze models.\n",
    "\n",
    "Analysis:\n",
    "  --analyze_list INT [INT ...]\n",
    "                           [2 3 4 5 6 7 8 9 10 11 12 13] list of numbers representing the\n",
    "                           analysis to be done. Choose between: 0) do nothing 1) optimization\n",
    "                           plot 2) correlation real/models 3) z-score plot 4) constraints 5)\n",
    "                           objective function 6) centroid 7) consistency 8) density 9) contact\n",
    "                           map 10) walking angle 11) persistence length 12) accessibility 13)\n",
    "                           interaction\n",
    "  --not_write_cmm          [False] do not generate cmm files for each model (Chimera input)\n",
    "  --not_write_xyz          [False] do not generate xyz files for each model (3D coordinates)\n",
    "  --not_write_json         [False] do not generate json file.\n",
    "\n",
    "Running jobs:\n",
    "  --smooth_factor INT      Hi-C matrix smoothing value of the mean kernel for pTADbit. Useful\n",
    "                           in case of using matrices with low sequencing depth\n",
    "  -C CPUS, --cpu CPUS      [32] Maximum number of CPU cores available in the execution host. If\n",
    "                           higher than 1, tasks with multi-threading capabilities will enabled\n",
    "                           (if 0 all available) cores will be used\n",
    "  --job_list               generate a list of commands stored in a file named joblist_HASH.q\n",
    "                           (where HASH is replaced by a string specific to the parameters\n",
    "                           used). note that dcutoff will never be split as it does not require\n",
    "                           to re-run models.\n",
    "  --nmodels_per_job INT    Number of models per distributed job.\n",
    "  --cpus_per_job INT       Number of cpu nodes per distributed job.\n",
    "  --concurrent_jobs INT    Number of concurrent jobs in distributed mode.\n",
    "  --timeout_job INT        Time to wait for a concurrent jobs to finish before canceling it in\n",
    "                           distributed mode.\n",
    "  --script_cmd STR         Command to call the jobs in distributed mode.\n",
    "  --script_args STR        Argumnets to script_cmd to call the jobs in distributed mode.\n",
    "  --script_template STR    Template to generate a file that script_cmd will call for each job\n",
    "                           in distributed mode. Each __file__ marker in the template will be\n",
    "                           replacedby the job file __name__ with the name and __dir__ with the\n",
    "                           folder.\n",
    "  --tmpdb PATH             if provided uses this directory to manipulate the database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TADbit merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Load two working directories with different Hi-C data samples and merges them into a new\n",
    "working directory generating some statistics.\n",
    "\n",
    "usage: tadbit merge [-h] [-w PATH] [-w1 PATH] [-w2 PATH] [--bam1 PATH] [--noX] [--bam2 PATH]\n",
    "                    [-C CPUS] [-r INT] [--skip_comparison] [--skip_merge]\n",
    "                    [--save STR [STR ...]] [--jobid1 INT] [--jobid2 INT] [--force] [--norm]\n",
    "                    [--biases1 PATH] [--biases2 PATH] [--filter INT [INT ...]]\n",
    "                    [--samtools PATH] [--tmpdb PATH]\n",
    "\n",
    "optional arguments:\n",
    "  -h, --help               show this help message and exit\n",
    "\n",
    "General options:\n",
    "  -w PATH, --workdir PATH  path to a new output folder\n",
    "  -w1 PATH, --workdir1 PATH\n",
    "                           path to working directory of the first HiC data sample to merge\n",
    "  -w2 PATH, --workdir2 PATH\n",
    "                           path to working directory of the second HiC data sample to merge\n",
    "  --bam1 PATH              path to the first TADbit-generated BAM file with all reads (other\n",
    "                           wise the tool will guess from the working directory database)\n",
    "  --noX                    no display server (X screen)\n",
    "  --bam2 PATH              path to the second TADbit-generated BAM file with all reads (other\n",
    "                           wise the tool will guess from the working directory database)\n",
    "  -C CPUS, --cpus CPUS     [32] Maximum number of CPU cores available in the execution host. If\n",
    "                           higher than 1, tasks with multi-threading capabilities will enabled\n",
    "                           (if 0 all available) cores will be used\n",
    "  -r INT, --resolution INT\n",
    "                           resolution at which to do the comparison, and generate the matrices.\n",
    "  --skip_comparison        skip the comparison between replicates (faster). Comparisons are\n",
    "                           performed at 3 levels 1- comparing first diagonals of each\n",
    "                           experiment (and generating SCC score and standard deviation see\n",
    "                           https://doi.org/10.1101/gr.220640.117) 2- Comparing the first\n",
    "                           eigenvectors of input experiments 3- Generates reproducibility score\n",
    "                           using function from https://doi.org/10.1093/bioinformatics/btx152\n",
    "  --skip_merge             skip the merge of replicates (faster).\n",
    "  --save STR [STR ...]     [genome] save genomic or chromosomic matrix.\n",
    "  --jobid1 INT             Use as input data generated by a job with a given jobid. Use tadbit\n",
    "                           describe to find out which.\n",
    "  --jobid2 INT             Use as input data generated by a job with a given jobid. Use tadbit\n",
    "                           describe to find out which.\n",
    "  --force                  overwrite previously run job\n",
    "  --norm                   compare normalized matrices\n",
    "  --biases1 PATH           path to file with precalculated biases by columns\n",
    "  --biases2 PATH           path to file with precalculated biases by columns\n",
    "  --filter INT [INT ...]   [[1, 2, 3, 4, 6, 7, 9, 10]] Use filters to define a set os valid\n",
    "                           pair of reads e.g.: '--apply 1 2 3 4 8 9 10'. Where these\n",
    "                           numberscorrespond to: 1: self-circle, 2: dangling-end, 3: error, 4:\n",
    "                           extra dangling-end, 5: too close from RES, 6: too short, 7: too\n",
    "                           large, 8: over-represented, 9: duplicated, 10: random breaks, 11:\n",
    "                           trans-chromosomic\n",
    "  --samtools PATH          path samtools binary\n",
    "  --tmpdb PATH             if provided uses this directory to manipulate the database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TADbit describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Describe jobs and results in a given working directory\n",
    "\n",
    "usage: tadbit describe [-h] [-w PATH] [--noX] [-t  [...]] [-T  [...]] [-j INT [INT ...]]\n",
    "                       [-W STR [STR ...]] [-s STR [STR ...]] [--tmpdb PATH] [--tsv] [-o OUTPUT]\n",
    "\n",
    "optional arguments:\n",
    "  -h, --help               show this help message and exit\n",
    "\n",
    "General options:\n",
    "  -w PATH, --workdir PATH  path to working directory (generated with the tool tadbit map)\n",
    "  --noX                    no display server (X screen)\n",
    "  -t  [ ...], --tables  [ ...]\n",
    "                           [['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12',\n",
    "                           '13']] what tables to show, write either the sequence of names or\n",
    "                           indexes, according to this list: 1: paths, 2: jobs, 3:\n",
    "                           mapped_outputs, 4: mapped_inputs, 5: parsed_outputs, 6:\n",
    "                           intersection_outputs, 7: filter_outputs, 8: normalize_outputs, 9:\n",
    "                           merge_stats, 10: merge_outputs, 11: segment_outputs, 12: models, 13:\n",
    "                           modeled_regions\n",
    "  -T  [ ...], --skip_tables  [ ...]\n",
    "                           [[]] what tables NOT to show, write either the sequence of names or\n",
    "                           indexes, according to this list: 1: paths, 2: jobs, 3:\n",
    "                           mapped_outputs, 4: mapped_inputs, 5: parsed_outputs, 6:\n",
    "                           intersection_outputs, 7: filter_outputs, 8: normalize_outputs, 9:\n",
    "                           merge_stats, 10: merge_outputs, 11: segment_outputs, 12: models, 13:\n",
    "                           modeled_regions\n",
    "  -j INT [INT ...], --jobids INT [INT ...]\n",
    "                           Display only items matching these jobids.\n",
    "  -W STR [STR ...], --where STR [STR ...]\n",
    "                           Select rows. List pairs of keywords (column header) and values to\n",
    "                           filter results. For example to get only results where \"18\" appears\n",
    "                           in the column \"Chromosome\", the option should be set as: `-W\n",
    "                           Chromosome,18`\n",
    "  -s STR [STR ...], --select STR [STR ...]\n",
    "                           Select columns. List the keyword (column headers) to be displayed.\n",
    "                           E.g. to show only the colmns JobIds: `-s Jobids`\n",
    "  --tmpdb PATH             if provided uses this directory to manipulate the database\n",
    "  --tsv                    Print output in tab separated format\n",
    "  -o OUTPUT, --output OUTPUT\n",
    "                           Writes output in specified file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TADbit clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Delete jobs and results of a given list of jobids in a given directories\n",
    "\n",
    "usage: tadbit clean [-h] [-w PATH] [-j INT [INT ...]] [--delete] [--compress] [--noX]\n",
    "                    [--change_workdir PATH] [--tmpdb PATH]\n",
    "\n",
    "optional arguments:\n",
    "  -h, --help               show this help message and exit\n",
    "  --change_workdir PATH    In case folder was moved, input the new path\n",
    "\n",
    "General options:\n",
    "  -w PATH, --workdir PATH  path to working directory (generated with the tool tadbit mapper)\n",
    "  -j INT [INT ...], --jobids INT [INT ...]\n",
    "                           jobids of the files and entries to be removed\n",
    "  --delete                 delete files, otherwise only DB entries.\n",
    "  --compress               compress files and update paths accordingly\n",
    "  --noX                    no display server (X screen)\n",
    "  --tmpdb PATH             if provided uses this directory to manipulate the database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TADbit import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Import Hi-C data to TADbit toy BAM\n",
    "\n",
    "usage: tadbit import [-h] -w PATH -r INT [--format {text,matrix,cooler}] -i STR [-c]\n",
    "                     [--tmpdb PATH] [-C CPUS] [--samtools PATH]\n",
    "\n",
    "optional arguments:\n",
    "  -h, --help               show this help message and exit\n",
    "\n",
    "Required options:\n",
    "  -w PATH, --workdir PATH  path to working directory (generated with the tool tadbit mapper)\n",
    "  -r INT, --resolution INT\n",
    "                           resolution at which to output matrices\n",
    "  --format {text,matrix,cooler}\n",
    "                           [text] can be any of [text, matrix, cooler]\n",
    "  -i STR, --input STR      path to input file\n",
    "\n",
    "General options:\n",
    "  -c , --coord             Coordinate of the region to import. By default all genome, arguments\n",
    "                           can be either one chromosome name, or the coordinate in the form:\n",
    "                           \"-c chr3:110000000-120000000\"\n",
    "  --tmpdb PATH             if provided uses this directory to manipulate the database\n",
    "  -C CPUS, --cpus CPUS     [32] Maximum number of CPU cores available in the execution host. If\n",
    "                           higher than 1, tasks with multi-threading capabilities will enabled\n",
    "                           (if 0 all available) cores will be used\n",
    "  --samtools PATH          path samtools binary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TADbit export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Export Hi-C data to other formats\n",
    "\n",
    "usage: tadbit export [-h] -w PATH -r INT [--format {text,matrix,cooler,hic}] -o STR\n",
    "                     [--bam PATH] [-j INT] [--force] [-q] [--tmpdb PATH] [--nchunks NCHUNKS]\n",
    "                     [-C CPUS] [--chr_name STR [STR ...]] [--juicerjar PATH] [--rownames] [-c]\n",
    "                     [-c2] [--biases PATH] [--norm] [-F INT [INT ...]]\n",
    "\n",
    "optional arguments:\n",
    "  -h, --help               show this help message and exit\n",
    "\n",
    "Required options:\n",
    "  -w PATH, --workdir PATH  path to working directory (generated with the tool tadbit mapper)\n",
    "  -r INT, --resolution INT\n",
    "                           resolution at which to output matrices\n",
    "  --format {text,matrix,cooler,hic}\n",
    "                           [text] can be any of [text, matrix, cooler, hic]\n",
    "  -o STR, --output STR     path to output file\n",
    "\n",
    "General options:\n",
    "  --bam PATH               path to a TADbit-generated BAM file with all reads (other wise the\n",
    "                           tool will guess from the working directory database)\n",
    "  -j INT, --jobid INT      Use as input data generated by a job with a given jobid. Use tadbit\n",
    "                           describe to find out which.\n",
    "  --force                  overwrite previously run job\n",
    "  -q, --quiet              remove all messages\n",
    "  --tmpdb PATH             if provided uses this directory to manipulate the database\n",
    "  --nchunks NCHUNKS        maximum number of chunks into which to cut the BAM\n",
    "  -C CPUS, --cpus CPUS     [32] Maximum number of CPU cores available in the execution host. If\n",
    "                           higher than 1, tasks with multi-threading capabilities will enabled\n",
    "                           (if 0 all available) cores will be used\n",
    "  --chr_name STR [STR ...]\n",
    "                           [fasta header] chromosome name(s). Order of chromosomes in the\n",
    "                           output matrices.\n",
    "  --juicerjar PATH         path to the juicer tools jar file needed to export matrices to hic\n",
    "                           format (check https://github.com/aidenlab/juicer/wiki/Download).\n",
    "                           Note that you also need java available in the path.\n",
    "\n",
    "Read filtering options:\n",
    "  -F INT [INT ...], --filter INT [INT ...]\n",
    "                           [[1, 2, 3, 4, 6, 7, 9, 10]] Use filters to define a set of valid\n",
    "                           pair of reads e.g.: '--filter 1 2 3 4 8 9 10'. Where these numbers\n",
    "                           correspond to: 0: nothing, 1: self-circle, 2: dangling-end, 3:\n",
    "                           error, 4: extra dangling-end, 5: too close from RES, 6: too short,\n",
    "                           7: too large, 8: over-represented, 9: duplicated, 10: random breaks,\n",
    "                           11: trans-chromosomic\n",
    "\n",
    "Normalization options:\n",
    "  --biases PATH            path to file with pre-calculated biases by columns\n",
    "  --norm                   export normalized matrix\n",
    "\n",
    "Output options:\n",
    "  --rownames               To store row names in the output text matrix. WARNING: when non-\n",
    "                           matrix, results in two extra columns\n",
    "  -c , --coord             Coordinate of the region to retrieve. By default all genome,\n",
    "                           arguments can be either one chromosome name, or the coordinate in\n",
    "                           the form: \"-c chr3:110000000-120000000\"\n",
    "  -c2 , --coord2           Coordinate of a second region to retrieve the matrix in the\n",
    "                           intersection with the first region."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

"""

information needed

 - path working directory with parsed reads

"""
from argparse                    import HelpFormatter
from pytadbit import load_hic_data_from_reads
from pytadbit.utils.sqlite_utils import already_run, digest_parameters
from pytadbit.utils.file_handling import mkdir
from os import path
import sqlite3 as lite
import time

DESC = 'normalize Hi-C data and write results to file as matrices'

def run(opts):
    check_options(opts)
    launch_time = time.localtime()


    param_hash = digest_parameters(opts)

    mreads = path.join(opts.workdir, load_parameters_fromdb(opts))

    hic_data = load_hic_data_from_reads(mreads, opts.reso)

    print 'Get poor bins...'
    try:
        hic_data.filter_columns(perc_zero=99)
    except ValueError:
        hic_data.filter_columns(perc_zero=100)

    mkdir(path.join(opts.workdir, '04_normalization'))

    out_bad = open(path.join(opts.workdir, '04_normalization',
                             'bad_columns_%s.tsv' %param_hash), 'w')
    out_bad.write('\n'.join([str(i) for i in hic_data.bads.keys()]))
    out_bad.close()

    # Identify biases
    print 'Get biases using ICE...'
    try:
        hic_data.normalize_hic(silent=False, max_dev=0.1, iterations=0)
        normalized = True
    except ZeroDivisionError:
        normalized = False
    cis_trans_1 = hic_data.cis_trans_ratio(normalized=False)
    cis_trans_2 = hic_data.cis_trans_ratio(normalized=False, diagonal=False)
    if normalized:
        cis_trans_3 = hic_data.cis_trans_ratio(normalized=True)
        cis_trans_4 = hic_data.cis_trans_ratio(normalized=True, diagonal=False)
    else:
        cis_trans_3 = 'NaN'
        cis_trans_4 = 'NaN'
        
    print 'Cis/Trans ratio not norm, yes diag:', cis_trans_1
    print 'Cis/Trans ratio not norm, not diag:', cis_trans_2
    print 'Cis/Trans ratio yes norm, yes diag:', cis_trans_3
    print 'Cis/Trans ratio yes norm, not diag:', cis_trans_4

    finish_time = time.localtime()

    # save_to_db(opts, launch_time, finish_time)

def save_to_db(opts,
               launch_time, finish_time):
    con = lite.connect(path.join(opts.workdir, 'trace.db'))
    with con:
        cur = con.cursor()

def load_parameters_fromdb(opts):
    con = lite.connect(path.join(opts.workdir, 'trace.db'))
    with con:
        cur = con.cursor()
        if not opts.jobid:
            # get the JOBid of the parsing job
            cur.execute("""
            select distinct Id from JOBs
            where Type = 'Filter'
            """)
            jobids = cur.fetchall()
            if len(jobids) > 1:
                raise Exception('ERROR: more than one possible input found, use'
                                '"tadbit describe" and select corresponding '
                                'jobid with --jobid')
        parse_jobid = jobids[0][0]
        # fetch path to parsed BED files
        cur.execute("""
        select distinct Path from PATHs
        where JOBid = %d and Type = '2D_BED'
        """ % parse_jobid)
        return cur.fetchall()[0][0]

def populate_args(parser):
    """
    parse option from call
    """
    parser.formatter_class=lambda prog: HelpFormatter(prog, width=95,
                                                      max_help_position=27)

    glopts = parser.add_argument_group('General options')

    glopts.add_argument('-w', '--workdir', dest='workdir', metavar="PATH",
                        action='store', default=None, type=str, required=True,
                        help='''path to working directory (generated with the
                        tool tadbit mapper)''')

    glopts.add_argument('-r', '--resolution', dest='reso', metavar="INT",
                        action='store', default=None, type=int, required=True,
                        help='''resolution at which to output matrices''')

    glopts.add_argument('--normalization', dest='resolution', metavar="STR",
                        action='store', default='ICE', nargs='+', type=str,
                        choices=['ICE', 'EXP'],
                        help='''[%(default)s] normalization(s) to apply. Order matters.''')

    glopts.add_argument('--save', dest='save', metavar="STR",
                        action='store', default='genome', nargs='+', type=str,
                        choices=['genome', 'chromosomes'],
                        help='''[%(default)s] save genomic or chromosomic matrix.''')

    glopts.add_argument('--jobid', dest='jobid', metavar="INT",
                        action='store', default=None, type=int,
                        help='''Use as input data generated by a job with a given
                        jobid. Use tadbit describe to find out which.''')    

    glopts.add_argument('--force', dest='force', action='store_true',
                      default=False,
                      help='overwrite previously run job')

    parser.add_argument_group(glopts)

def check_options(opts):

    # check resume
    if not path.exists(opts.workdir) and opts.resume:
        print ('WARNING: can use output files, found, not resuming...')
        opts.resume = False

    if already_run(opts) and not opts.force:
        exit('WARNING: exact same job already computed, see JOBs table above')
